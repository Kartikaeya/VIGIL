{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "from pycocotools.coco import COCO\n",
    "import os, sys, zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "import cv2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=40.20s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=21.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# load annotations\n",
    "coco = COCO(\"../../annotations/instances_train2017.json\");\n",
    "coco_kpts = COCO(\"../../annotations/person_keypoints_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image ids of images containing person\n",
    "person_IDs = coco.getCatIds(catNms = [\"person\"])\n",
    "img_IDs = coco.getImgIds(catIds = person_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64115\n"
     ]
    }
   ],
   "source": [
    "print(len(img_IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(anns):\n",
    "    coordinates = np.zeros(((int)(len(anns)/2), 2))\n",
    "    for i in range(0, (int)(len(anns)/2)):\n",
    "        coordinates[i][0] = anns[2*i]\n",
    "        coordinates[i][1] = anns[(2*i) +1]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keypoints.csv', mode='w',newline='') as keypoints:\n",
    "    keypts_writer = csv.writer(keypoints, delimiter = ' ')\n",
    "    for i in range(14042, 20000):\n",
    "        #read img\n",
    "        img = coco.loadImgs(img_IDs[i])[0]\n",
    "        I = io.imread(img['coco_url'])\n",
    "        plt.imshow(I)\n",
    "        \n",
    "        # the average height found was 484 -> 480\n",
    "        # the average width found was 578 -> 580\n",
    "        # these height, width will be used for resizing training images\n",
    "        height = I.shape[0]\n",
    "        width = I.shape[1]\n",
    "        \n",
    "        # now get the annotations for segmentation\n",
    "        annIds = coco.getAnnIds(imgIds=img['id'], catIds = person_IDs, iscrowd = None)\n",
    "        anns = coco.loadAnns(annIds)\n",
    "\n",
    "        # annotations for keypoint detection\n",
    "        annIds = coco_kpts.getAnnIds(imgIds=img['id'])\n",
    "        anns_kpts = coco_kpts.loadAnns(annIds)\n",
    "#         coco_kpts.showAnns(anns)\n",
    "\n",
    "\n",
    "        # get the annotations corresponding to the segmentation having the maximum area\n",
    "#         max_area = 0\n",
    "#         max_area_index = 0\n",
    "#         for j in range(0, len(anns)):\n",
    "#             if(anns[j]['area'] > max_area):\n",
    "#                 max_area = anns[j]['area']\n",
    "#                 max_area_index = j\n",
    "                \n",
    "#         print(max_area)\n",
    "#         print(max_area_index)\n",
    "        if(anns[0]['area'] < 10000):\n",
    "            continue\n",
    "        \n",
    "        keypts_writer.writerow([(int)(anns_kpts[0]['keypoints'][15]*580/width), (int)(anns_kpts[0]['keypoints'][16]*480/height), anns_kpts[0]['keypoints'][17]])\n",
    "        keypts_writer.writerow([(int)(anns_kpts[0]['keypoints'][18]*580/width), (int)(anns_kpts[0]['keypoints'][19]*480/height), anns_kpts[0]['keypoints'][20]])\n",
    "\n",
    "        # get coordinates of segment corresponding to maximum area\n",
    "        cord_segm = get_coordinates(anns[0]['segmentation'][0])\n",
    "\n",
    "        # create mask\n",
    "        mask = np.zeros(I.shape[:2] , np.uint8)\n",
    "\n",
    "        cv2.fillConvexPoly(mask,cord_segm.astype(np.int32), color = 1)\n",
    "        masked_img = cv2.bitwise_and(I, I, mask = mask.astype(np.uint8))\n",
    "\n",
    "        # save the masked image\n",
    "        masked_img = cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB)\n",
    "        masked_img = cv2.resize(masked_img , (580, 480))\n",
    "#         masked_img = cv2.circle(masked_img,((int)(anns_kpts[0]['keypoints'][15]*580/width),(int)(anns_kpts[0]['keypoints'][16]*480/height) ),5, [255, 0, 0], -1)\n",
    "#         masked_img = cv2.circle(masked_img,((int)(anns_kpts[0]['keypoints'][18]*580/width),(int)(anns_kpts[0]['keypoints'][19]*480/height) ),5, [255, 0, 0], -1)\n",
    "        cv2.imwrite(\"D:/train_images/\" + str(str(i).rjust(6, '0')) + \".jpg\", masked_img)\n",
    "\n",
    "#         plt.imshow(masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
